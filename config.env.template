# RHOAI Ops Buddy Configuration Template
# Copy this to config.env and fill in your values
# Format: KEY=value (no exports, for Podman Compose compatibility)

# MCP servers configuration (mounted into container at /app/config/)
# The mcp_servers.json file must exist - copy from mcp_servers.template.json
MCP_CONFIG_PATH=/app/config/mcp_servers.json

# Jenkins Configuration
# JENKINS_URL options:
#   - For Jenkins on same host: http://host.containers.internal:8080
#   - For remote Jenkins: http://jenkins-hostname-or-ip:8080
#   - For containerized Jenkins: http://jenkins-container-name:8080
JENKINS_URL=http://host.containers.internal:8080
JENKINS_USER=your-jenkins-username
JENKINS_PASSWORD=your-jenkins-password
JENKINS_SERVER_PATH=/home/your-user/path/to/rhoai-jenkins-mcp
CLUSTER_MONITOR_PATH=/home/your-user/path/to/rhoai-cluster-monitor-mcp

# Hive Cluster Configuration (for cluster monitor)
# Path to your hive kubeconfig file on the host
HIVE_KUBECONFIG_HOST=/home/your-user/.kube/hive.yaml
# Kubernetes context to use for Hive cluster
HIVE_CONTEXT=hive-cluster

# LLM Configuration
LLM_BASE_URL=https://your-llm-endpoint
LLM_API_KEY=your-llm-api-key
LLM_MODEL=your-llm-model
LLM_TEMPERATURE=0.7

# LangGraph Configuration
# Internal URL (for server-side API passthrough)
LANGGRAPH_API_URL=http://localhost:8000

# Agent Chat UI Configuration
# The public API URL that the browser will use to connect to LangGraph
# For local: http://localhost:8000
# For remote server: http://your-server-hostname:8000
NEXT_PUBLIC_API_URL=http://localhost:8000

# LangSmith API key for tracing and monitoring (required)
LANGSMITH_API_KEY=lsv2_your_api_key